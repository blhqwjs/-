{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from transformers import Trainer, TrainingArguments\n",
    "import torch\n",
    "\n",
    "# 下载停用词（如果还没有下载过）\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# 定义数据预处理函数\n",
    "def preprocess_text(text):\n",
    "    # 小写化\n",
    "    text = text.lower()\n",
    "    # 去除特殊字符和数字，保留汉字和英文字符\n",
    "    text = re.sub(r'[^a-zA-Z\\u4e00-\\u9fa5]', ' ', text)\n",
    "    return text\n",
    "\n",
    "# 读取数据集\n",
    "df = pd.read_excel('tieba.xlsx')  # 替换为你的文件名\n",
    "\n",
    "# 假设 '标题' 列是你的文本，'分类（杂谈1、互助2、生活分享3、交流合作4、闲置5）' 列是你的标注数据\n",
    "texts = df['标题'].tolist()\n",
    "labels = df['分类（杂谈1、互助\\t2、生活分享3、交流合作4、闲置5）'].tolist()\n",
    "\n",
    "# 数据预处理\n",
    "processed_texts = [preprocess_text(text) for text in texts]\n",
    "\n",
    "# 将标签转换为整数并减去 1\n",
    "labeled_labels = [int(label) - 1 for label in labels if pd.notna(label)]\n",
    "labeled_texts = [text for text, label in zip(processed_texts, labels) if pd.notna(label)]\n",
    "\n",
    "# 确保文本和标签的长度一致\n",
    "assert len(labeled_texts) == len(labeled_labels), \"文本和标签长度不一致\"\n",
    "\n",
    "# 将手动标注的数据划分为训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    labeled_texts, labeled_labels, test_size=0.2, random_state=42, stratify=labeled_labels)\n",
    "\n",
    "# 加载BERT分词器\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-chinese')\n",
    "\n",
    "# 对文本进行编码\n",
    "train_encodings = tokenizer(X_train, truncation=True, padding=True, max_length=128)\n",
    "test_encodings = tokenizer(X_test, truncation=True, padding=True, max_length=128)\n",
    "\n",
    "# 创建数据集类\n",
    "class TextDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "# 创建训练集和测试集\n",
    "train_dataset = TextDataset(train_encodings, y_train)\n",
    "test_dataset = TextDataset(test_encodings, y_test)\n",
    "\n",
    "# 加载BERT模型\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-chinese', num_labels=5)\n",
    "\n",
    "# 设置训练参数\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results2', #定义模型存放位置\n",
    "    num_train_epochs=4, \n",
    "    #设置训练的 epoch 数，即重复学习次数，初始为3，当调整为10时，在第五次后出现了过拟合现象，所以采用：4次\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=64,\n",
    "    warmup_steps=500, #定义学习率预热的步骤数\n",
    "    weight_decay=0.01, #权重衰减系数（也称为 L2 正则化），用于防止过拟合\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    # evaluation_strategy=\"epoch\" # 未来版本可能不再支持\n",
    "    eval_strategy=\"epoch\",  \n",
    ")\n",
    "\n",
    "# 使用Trainer API进行训练\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    ")\n",
    "\n",
    "# 训练模型\n",
    "trainer.train()\n",
    "\n",
    "# 预测测试集的分类\n",
    "predictions, labels, _ = trainer.predict(test_dataset)\n",
    "predicted_labels = predictions.argmax(-1)\n",
    "\n",
    "# 打印分类报告\n",
    "print(\"分类报告：\")\n",
    "print(classification_report(y_test, predicted_labels))\n",
    "\n",
    "# 将预测的标签和原始文本保存到 DataFrame 中\n",
    "output_df = pd.DataFrame({\n",
    "    '标题': X_test,\n",
    "    '真实标签': y_test,\n",
    "    '预测标签': predicted_labels\n",
    "})\n",
    "\n",
    "# 将结果保存到 Excel 文件\n",
    "output_df.to_excel('prediction_results.xlsx', index=False)\n",
    "\n",
    "print(\"预测结果已保存到 'prediction_results.xlsx'\")\n",
    "\n",
    "# 对未标注的数据进行预测并保存\n",
    "\n",
    "# 提取未标注的数据\n",
    "unlabeled_texts = df[df['分类（杂谈1、互助\\t2、生活分享3、交流合作4、闲置5）'].isna()]['标题'].tolist()\n",
    "\n",
    "# 打印未标注的数据数量和内容，确保数据被正确提取\n",
    "print(f\"未标注的数据数量: {len(unlabeled_texts)}\")\n",
    "# print(f\"未标注的文本数据: {unlabeled_texts}\")\n",
    "\n",
    "\n",
    "# 如果有未标注的数据，进行处理\n",
    "if len(unlabeled_texts) > 0:\n",
    "    # 对未标注的文本进行编码\n",
    "    unlabeled_encodings = tokenizer(unlabeled_texts, truncation=True, padding=True, max_length=128)\n",
    "\n",
    "    # 创建未标注数据集\n",
    "    class UnlabeledTextDataset(torch.utils.data.Dataset):\n",
    "        def __init__(self, encodings):\n",
    "            self.encodings = encodings\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "            return item\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.encodings['input_ids'])\n",
    "\n",
    "    # 创建未标注数据集\n",
    "    unlabeled_dataset = UnlabeledTextDataset(unlabeled_encodings)\n",
    "\n",
    "    # 使用训练好的模型对未标注数据进行预测\n",
    "    predictions, _, _ = trainer.predict(unlabeled_dataset)\n",
    "    predicted_labels = predictions.argmax(-1)\n",
    "\n",
    "    # 将预测的标签和未标注文本保存到 DataFrame 中\n",
    "    unlabeled_df = pd.DataFrame({\n",
    "        '标题': unlabeled_texts,\n",
    "        '预测标签': predicted_labels\n",
    "    })\n",
    "\n",
    "    # 将未标注数据的预测结果填充到原始 DataFrame 中对应的位置\n",
    "    df.loc[df['分类（杂谈1、互助\\t2、生活分享3、交流合作4、闲置5）'].isna(), '分类（杂谈1、互助\\t2、生活分享3、交流合作4、闲置5）'] = predicted_labels + 1\n",
    "\n",
    "    # 将包含预测结果的原始数据保存到 Excel 文件\n",
    "    df.to_excel('prediction_results_with_unlabeled.xlsx', index=False)\n",
    "\n",
    "    print(\"未标注数据的预测结果已保存到 '重复5次的预测数据.xlsx'\")\n",
    "else:\n",
    "    print(\"没有未标注的数据。\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
